{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self,n_classes):\n",
    "        super().__init__()\n",
    "        self.fc_in = nn.Linear(in_features=4, out_features=5)\n",
    "        self.fc2 = nn.Linear(in_features=5, out_features=7)\n",
    "        self.fc_out = nn.Linear(in_features=7, out_features=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc_in(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train(model, train_loader,valid_loader, optimizer, criterion, device,epochs = 10):\n",
    "\n",
    "    history = {'train':{'loss':[],'accuracy':[]}, 'valid':{'loss':[],'accuracy':[]}}\n",
    "    n = len(train_loader)\n",
    "    model.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        Loss_epoch = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        evaluation_train = {'accuracy':0, 'loss':0}\n",
    "        for idx, data in enumerate(tqdm(train_loader)):\n",
    "            input, labels = data[0].to(device), data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input)\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            Loss_epoch += loss.item()*len(labels)\n",
    "            correct += accuracy(output, labels)*len(labels)\n",
    "            total += len(labels)\n",
    "        # Loss_history.append(Loss_epoch/n)\n",
    "        evaluation_train['accuracy'] = correct/total\n",
    "        evaluation_train['loss'] =  Loss_epoch/total\n",
    "        # evaluation_train = evaluate(model, train_loader,criterion, device)\n",
    "        evaluation_valid,_ = evaluate(model, valid_loader,criterion, device)\n",
    "        print(f'train: {evaluation_train}, valid: {evaluation_valid}')\n",
    "        history['train']['accuracy'].append(evaluation_train['accuracy'])\n",
    "        history['train']['loss'].append(evaluation_train['loss'])\n",
    "\n",
    "\n",
    "\n",
    "        history['valid']['loss'].append(evaluation_valid['loss'])\n",
    "        history['valid']['accuracy'].append(evaluation_valid['accuracy'])\n",
    "    return history\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    _, preds = torch.max(output, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds)).item()\n",
    "\n",
    "def evaluate(model,data_loader, criterion, device,return_preds = False):\n",
    "    model.eval()\n",
    "    Accuracy_history = []\n",
    "    Loss_history = []\n",
    "    PREDS = []\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(data_loader):\n",
    "            input, target = data[0].to(device), data[1].to(device)\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            Accuracy_history.append(accuracy(output, target))\n",
    "            Loss_history.append(loss.item())\n",
    "            if return_preds:\n",
    "                PREDS.extend(torch.max(output, dim=1)[1].tolist())\n",
    "    return {'accuracy': torch.mean(torch.Tensor(Accuracy_history)).item(), 'loss': torch.mean(torch.Tensor(Loss_history)).item()}, PREDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2 as tt\n",
    "from sklearn.model_selection import train_test_split\n",
    "class IRISDataset(Dataset):\n",
    "    def __init__(self, x, y, transform=None):\n",
    "        self.x = x#torch.Tensor(x,).unsqueeze(1).type(torch.FloatTensor)\n",
    "        self.y = y#torch.Tensor(y).type(torch.LongTensor)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "iris_X,iris_Y = datasets.load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 190.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.32592592967881096, 'loss': 1.1055783342432093}, valid: {'accuracy': 0.30000001192092896, 'loss': 1.092227578163147}\n",
      "Kfold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 189.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.3407407463700683, 'loss': 1.0917026466793485}, valid: {'accuracy': 0.6499999761581421, 'loss': 1.0773370265960693}\n",
      "Kfold: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 200.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.35555556306132563, 'loss': 1.0990378106081928}, valid: {'accuracy': 0.20000000298023224, 'loss': 1.1157479286193848}\n",
      "Kfold: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 288.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.3185185271280783, 'loss': 1.1069184850763392}, valid: {'accuracy': 0.5, 'loss': 1.0907020568847656}\n",
      "Kfold: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 202.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.3333333405079665, 'loss': 1.1038763346495453}, valid: {'accuracy': 0.5, 'loss': 1.0693655014038086}\n",
      "Kfold: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 275.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.30370371098871585, 'loss': 1.1056798873124298}, valid: {'accuracy': 0.4000000059604645, 'loss': 1.1005597114562988}\n",
      "Kfold: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 250.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.4814814936231684, 'loss': 1.0692539744906955}, valid: {'accuracy': 0.800000011920929, 'loss': 1.0223443508148193}\n",
      "Kfold: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 289.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.08888889076533141, 'loss': 1.1064394579993353}, valid: {'accuracy': 0.0, 'loss': 1.0996062755584717}\n",
      "Kfold: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 258.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.3333333405079665, 'loss': 1.0756211015913222}, valid: {'accuracy': 0.5, 'loss': 1.0427942276000977}\n",
      "Kfold: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/14 [00:00<?, ?it/s]c:\\Users\\KHADGA JYOTH ALLI\\.conda\\envs\\gpu\\lib\\site-packages\\torchvision\\transforms\\v2\\_container.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = transform(*inputs)\n",
      "100%|██████████| 14/14 [00:00<00:00, 297.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: {'accuracy': 0.4148148243074064, 'loss': 1.0827214276349102}, valid: {'accuracy': 0.550000011920929, 'loss': 1.0817434787750244}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "pipeline = make_pipeline(StandardScaler())\n",
    "\n",
    "kFold=KFold(n_splits=10,random_state=42,shuffle=True)\n",
    "for fold,(train_index,test_index) in enumerate(kFold.split(iris_X)):\n",
    "    print(f'Kfold: {fold}')\n",
    "    X_train, X_test, y_train, y_test = iris_X[train_index], iris_X[test_index], iris_Y[train_index], iris_Y[test_index]\n",
    "    \n",
    "    X_train = pipeline.fit_transform(X_train)\n",
    "    X_test = pipeline.transform(X_test)\n",
    "    \n",
    "    X_train_dataset = IRISDataset(X_train, y_train,tt.Compose([torch.tensor]))\n",
    "    X_test_dataset = IRISDataset(X_test, y_test,tt.Compose([torch.tensor]))\n",
    "\n",
    "    train_loader = DataLoader(X_train_dataset, batch_size=10, shuffle=True)\n",
    "    test_loader = DataLoader(X_test_dataset, batch_size=10, shuffle=False)\n",
    "    \n",
    "    model = SimpleMLP(3)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    history = train(model, train_loader, test_loader, optimizer, criterion, device,epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
